{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727d9170-72d6-432f-8ed9-8b15979f0728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title: Fig3----\n",
    "# A régler: Si on prend 1978 pas tous les fichiers dans une année donc pb\n",
    "# Normaliser? donnes entre 1980 et 210 \n",
    "# Arthur BARREAU: 06 Février 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fewer-lease",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "system(\"conda install -y r-sf=0.9_8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "piano-subcommittee",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "system(\"conda install -y r-terra=1.2_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "moral-keeping",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "system(\"conda install -y r-dplyr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "racial-butler",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "system(\"conda install -y r-stringr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "recovered-settle",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "system(\"conda install -y r-RColorBrewer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-fifth",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 1 LOAD LIBRARIES ----\n",
    "library(terra)\n",
    "library(dplyr)\n",
    "library(stringr)\n",
    "library(RColorBrewer)\n",
    "library(sf)\n",
    "library(jsonlite)  # Ajouter cette ligne pour lire le JSON\n",
    "\n",
    "# 2 VARIABLE ----\n",
    "months_days <- list(\n",
    "  Jan = 31, Feb = 28, Mar = 31, Apr = 30, May = 31, Jun = 30, \n",
    "  Jul = 31, Aug = 31, Sep = 30, Oct = 31, Nov = 30, Dec = 31\n",
    ")\n",
    "\n",
    "# 3 FUNCTION ----\n",
    "\n",
    "# Récupérer la liste des fichiers dans galaxy_inputs/month ou galaxy_inputs/year\n",
    "get_input_files <- function(input_path) {\n",
    "  input_files <- list.files(input_path, full.names = TRUE)\n",
    "  return(input_files)\n",
    "}\n",
    "\n",
    "# Validate the month and year\n",
    "validate_month_year <- function(month, year) {\n",
    "  if (!(month %in% names(months_days))) stop(\"Invalid month. Please enter a valid month.\")\n",
    "  if (is.na(year) || year < 1) stop(\"Invalid year. Please enter a valid year.\")\n",
    "  \n",
    "  return(months_days[[month]])\n",
    "}\n",
    "\n",
    "# Create directories for storing TIFF and Shapefile data\n",
    "create_directories <- function(year, month) {\n",
    "  tif_path <- file.path(\"tif_folder\", sprintf(\"%s_%s\", year, month))\n",
    "  zip_path <- \"zip_folder\"\n",
    "  shp_path <- \"shapefile_folder\"\n",
    "  dir.create(tif_path, showWarnings = FALSE, recursive = TRUE)\n",
    "  dir.create(zip_path, showWarnings = FALSE, recursive = TRUE)\n",
    "  dir.create(shp_path, showWarnings = FALSE, recursive = TRUE)\n",
    "  \n",
    "  return(list(tif_path = tif_path, zip_path = zip_path, shp_path = shp_path))\n",
    "}\n",
    "\n",
    "# Download daily TIFF files\n",
    "download_tiff_files <- function(path, year, start_month, days_in_month) {\n",
    "  month_index <- match(start_month, names(months_days))  \n",
    "  month_folder <- sprintf(\"%02d_%s\", month_index, start_month) \n",
    "  \n",
    "  for (day in 1:days_in_month) {\n",
    "    date_str <- sprintf(\"%s%02d%02d\", year, month_index, day)  \n",
    "    url <- paste0(\"https://noaadata.apps.nsidc.org/NOAA/G02135/south/daily/geotiff/\", year, \"/\", month_folder, \"/S_\", date_str, \"_concentration_v3.0.tif\")\n",
    "    destfile <- file.path(path, sprintf(\"S_%s_concentration.tif\", date_str))\n",
    "    \n",
    "    if (!file.exists(destfile)) {\n",
    "      tryCatch({\n",
    "        download.file(url, destfile)\n",
    "      }, error = function(e) {\n",
    "        message(\"Download failed for: \", url)\n",
    "      })\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# Compute the monthly mean raster\n",
    "compute_monthly_mean <- function(path, start_year, start_month) {\n",
    "  month_index <- match(start_month, names(months_days))\n",
    "  dir.create(\"data\", showWarnings = FALSE)\n",
    "  tif_files <- list.files(path, pattern = \"\\\\.tif$\", full.names = TRUE)\n",
    "  if (length(tif_files) > 0) {\n",
    "    rasters <- rast(tif_files)\n",
    "    rasters[rasters == 2550] <- NA  # Remplacer les valeurs 2550 par NA\n",
    "    mean_raster <- mean(rasters, na.rm = TRUE)  \n",
    "    output_raster <- sprintf(\"data/monthly_mean_%s_%02d.tif\", start_year, month_index)\n",
    "    writeRaster(mean_raster, output_raster, overwrite = TRUE)\n",
    "    return(mean_raster)\n",
    "  } else {\n",
    "    message(\"No files downloaded. Check URLs and connection.\")\n",
    "    return(NULL)\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "# Download and process shapefiles\n",
    "download_shapefiles <- function(zip_path, shp_path, start_month) {\n",
    "  month_index <- match(start_month, names(months_days))\n",
    "  start_day <- sum(unlist(months_days)[1:(month_index - 1)]) + 1\n",
    "  end_day <- start_day + months_days[[start_month]] - 1\n",
    "  \n",
    "  for (day in start_day:end_day) {\n",
    "    days <- sprintf(\"%03d\", day)\n",
    "    url <- paste0(\"https://noaadata.apps.nsidc.org/NOAA/G02135/south/daily/shapefiles/dayofyear_median/median_extent_S_\", days, \"_1981-2010_polyline_v3.0.zip\")\n",
    "    destfile <- file.path(zip_path, sprintf(\"median_extent_S_%s.zip\", days))\n",
    "    \n",
    "    tryCatch({\n",
    "      download.file(url, destfile)\n",
    "      unzip(destfile, exdir = shp_path)\n",
    "    }, error = function(e) {\n",
    "      message(\"Download failed for: \", url)\n",
    "    })\n",
    "  }\n",
    "}\n",
    "\n",
    "# Merge shapefiles and compute mean polygon\n",
    "process_shapefiles <- function(shp_path) {\n",
    "  shp_files <- list.files(shp_path, pattern = \"\\\\.shp$\", full.names = TRUE)\n",
    "  polygons <- lapply(shp_files, st_read)\n",
    "  merged_polygons <- do.call(st_union, polygons)\n",
    "  mean_polygon <- st_intersection(merged_polygons)\n",
    "  convex_hull <- st_convex_hull(mean_polygon)\n",
    "  return(list(merged_polygons = merged_polygons, convex_hull = convex_hull))\n",
    "}\n",
    "\n",
    "\n",
    "# Create color palettes and breaks for visualization\n",
    "create_colors_and_breaks <- function() {\n",
    "  breaks <- c(0,1, seq(150, 1000, by = 50),1050, 2531, 2541)\n",
    "  \n",
    "  # Vérifier que les breaks sont uniques et triés\n",
    "  breaks <- unique(sort(breaks))\n",
    "  \n",
    "  # Dégradé pour les glaciers (1 à 1000)\n",
    "  colors_glacier <- rev(c(\n",
    "    \"#F7FCFF\", \"#E4F4FE\", \"#D0ECFE\", \"#BCE4FE\", \"#A8DCFD\",\n",
    "    \"#94D5FD\", \"#7DCCFD\", \"#6AC4FC\", \"#57BCFC\", \"#45B4FC\",\n",
    "    \"#31ABFC\", \"#23A3FC\", \"#1A9BFC\", \"#1994F9\", \"#178CF2\",\n",
    "    \"#1684EB\", \"#137AE3\", \"#093C70\" ))\n",
    "  \n",
    "  # Définition des couleurs\n",
    "  colors <- c(\n",
    "    rgb(9, 60, 112, maxColorValue = 255),\n",
    "    colors_glacier,  \n",
    "    rgb(255, 255, 255, maxColorValue = 255),  # Dégradé bleu glacier (1 à 1000)\n",
    "    rgb(0, 0, 0, maxColorValue = 255),      # Ligne côtière noire (2530)\n",
    "    rgb(119, 119, 119, maxColorValue = 255) # Terre grise (2540)\n",
    "  )\n",
    "  if (length(colors) != length(breaks) - 1) stop(\"Number of colors must match number of defined classes.\")\n",
    "  return(list(colors = colors, breaks = breaks))\n",
    "}\n",
    "\n",
    "# Visualization and saving results\n",
    "save_plot <- function(raster, colors, breaks, polygons, year, month) {\n",
    "  #dir.create(\"result\", showWarnings = FALSE)\n",
    "  png(filename = sprintf(\"outputs/Fig3_%s_%s.png\", year, month), width = 800, height = 600)\n",
    "  plot(raster, col = colors, breaks = breaks, legend = FALSE, axes = FALSE, box = FALSE)\n",
    "  plot(st_geometry(polygons$merged_polygons), add = TRUE, pch = 21, col = 'red', cex = 1.5)\n",
    "  dev.off()\n",
    "}\n",
    "\n",
    "\n",
    "# 4 MAIN ----\n",
    "\n",
    "# Lire les paramètres depuis le fichier JSON\n",
    "json_path <- \"galaxy_inputs/galaxy_inputs.json\"\n",
    "json_data <- fromJSON(json_path)\n",
    "\n",
    "start_month <- json_data$month\n",
    "start_year <- json_data$year\n",
    "\n",
    "days_in_month <- validate_month_year(start_month, start_year)\n",
    "paths <- create_directories(start_year, start_month)\n",
    "\n",
    "download_tiff_files(paths$tif_path, start_year, start_month, days_in_month)\n",
    "mean_raster <- compute_monthly_mean(paths$tif_path, start_year, start_month)\n",
    "\n",
    "download_shapefiles(paths$zip_path, paths$shp_path, start_month)\n",
    "polygons <- process_shapefiles(paths$shp_path)\n",
    "\n",
    "color_breaks <- create_colors_and_breaks()\n",
    "save_plot(mean_raster, color_breaks$colors, color_breaks$breaks, polygons, start_year, start_month)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R [conda env:rlang-kernel]",
   "language": "R",
   "name": "conda-env-rlang-kernel-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
